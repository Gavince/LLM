{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c748b1a0-8550-4e2d-bdad-d47c0073bb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 07:42:58,436] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Optional, List\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from deepspeed import zero\n",
    "from deepspeed.runtime.zero.partition_parameters import ZeroParamStatus\n",
    "import transformers\n",
    "from transformers import Trainer, GPTQConfig, deepspeed\n",
    "from transformers.trainer_pt_utils import LabelSmoother\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from accelerate.utils import DistributedType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e105c-375c-4f03-aa1d-8fb530eb749b",
   "metadata": {},
   "source": [
    "## 参数解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8319ba00-e00e-485b-bdca-5d1b653e77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \n",
    "    model_name_or_path: Optional[str] = field(default=\"Qwen/Qwen-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d1e326-b6ed-4fd0-a756-55b3b9658d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460cd02f-40ce-4764-8549-425aa40517f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qwen/Qwen-7B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74075e90-d715-409c-b1b5-02b51a5772f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArguments(model_name_or_path='Qwen/Qwen-7B')\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9331d26c-294f-472d-bf51-25178a6b5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataArguments:\n",
    "    data_path: str = field(\n",
    "        default=None, metadata={\"help\": \"Path to the training data.\"}\n",
    "    )\n",
    "    eval_data_path: str = field(\n",
    "        default=None, metadata={\"help\": \"Path to the evaluation data.\"}\n",
    "    )\n",
    "    lazy_preprocess: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebaadf2e-f81a-41fb-b9b1-9de995afcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingArguments(transformers.TrainingArguments):\n",
    "    cache_dir: Optional[str] = field(default=None)\n",
    "    optim: str = field(default=\"adamw_torch\")\n",
    "    model_max_length: int = field(\n",
    "        default=8192,\n",
    "        metadata={\n",
    "            \"help\": \"Maximum sequence length. Sequences will be right padded (and possibly truncated).\"\n",
    "        },\n",
    "    )\n",
    "    use_lora: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24edf0f-8934-46f9-aed3-ca2e3e21e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LoraArguments:\n",
    "    lora_r: int = 64\n",
    "    lora_alpha: int = 16\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_target_modules: List[str] = field(\n",
    "        default_factory=lambda: [\"c_attn\", \"c_proj\", \"w1\", \"w2\"]\n",
    "    )\n",
    "    lora_weight_path: str = \"\"\n",
    "    lora_bias: str = \"none\"\n",
    "    q_lora: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5706e850-7302-4a5a-b214-920b2b57cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = transformers.HfArgumentParser(\n",
    "    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
