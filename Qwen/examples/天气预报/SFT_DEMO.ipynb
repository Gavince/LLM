{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f90c238-66c8-420f-9fd0-a5d4051dcae4",
   "metadata": {},
   "source": [
    "# 天气预报微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d3b4a-43af-43ec-afd1-545e15febfe8",
   "metadata": {},
   "source": [
    "## 加载1.8B Chat Int4模型\n",
    "在原有chat模型上进行参数微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97dfda11-fb3b-4c28-8bb0-8a1fe0c2eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 07:46:03,194 - modelscope - INFO - PyTorch version 2.1.2+cu121 Found.\n",
      "2024-03-01 07:46:03,196 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-03-01 07:46:03,319 - modelscope - INFO - Loading done! Current index file version is 1.12.0, with md5 db1505a3ac0bd41b605104b5cde0c395 and a total number of 964 components indexed\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3596ca1b-2c42-49a4-aef7-72accae331d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 07:46:04,558 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir = snapshot_download('qwen/Qwen-1_8B-Chat-Int4')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757b9f1c-f05c-4347-90bf-2af0c588db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '{\\'id\\': \\'identity_1\\', \\'conversations\\': [{\\'from\\': \\'user\\', \\'value\\': \\'\\\\n给定一句话：“你们1999年4月8日去金溪县玩吗？”，请你按步骤要求工作。\\\\n\\\\n步骤1：识别这句话中的城市和日期共2个信息\\\\n步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\\\\n\\\\n请问，这个JSON字符串是：\\\\n\\'}, {\\'from\\': \\'assistant\\', \\'value\\': \\'{\"city\": \"金溪县\", \"date\": \"1999-04-08\"}\\'}]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7af19df-0ed6-414b-89ff-28226945204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个JSON字符串是：\"{\\\"city\\\":\\\"金溪县\\\",\\\"date\\\":\\\"1999-04-08\\\"}\"。\n"
     ]
    }
   ],
   "source": [
    "response, _ = model.chat(tokenizer\n",
    "                         , prompt\n",
    "                         , history=None\n",
    "                        )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020af6b3-022e-4cad-967c-e8144e71780a",
   "metadata": {},
   "source": [
    "## 有效参数微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbb0900-6554-4751-bbc8-326fac486cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 城市数据\n",
    "with open('city.txt','r',encoding='utf-8') as fp:\n",
    "    city_list=fp.readlines()\n",
    "    city_list=[line.strip().split(' ')[1] for line in city_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6338a20-6c9c-49fa-9f5b-9c606d747260",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q='青岛4月6日下雨么?'\n",
    "\n",
    "prompt_template='''\n",
    "给定一句话：“%s”，请你按步骤要求工作。\n",
    "\n",
    "步骤1：识别这句话中的城市和日期共2个信息\n",
    "步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\n",
    "\n",
    "请问，这个JSON字符串是：\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65138cce-9cd6-4dcf-8d61-025a13864f6c",
   "metadata": {},
   "source": [
    "# 生成SFT微调数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d76f5-0008-42a1-a459-0d9d54d23ce6",
   "metadata": {},
   "source": [
    "Qwen的SFT数据格式要求:\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"id\": \"identity_0\",\n",
    "    \"conversations\": [\n",
    "      {\n",
    "        \"from\": \"user\",\n",
    "        \"value\": \"你好\"\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"assistant\",\n",
    "        \"value\": \"我是一个语言模型，我叫通义千问。\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9673d1-3359-41ef-b851-a4be82765701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import time \n",
    "\n",
    "Q_arr=[]\n",
    "A_arr=[]\n",
    "\n",
    "Q_list=[\n",
    "    ('{city}{year}年{month}月{day}日的天气','%Y-%m-%d'),\n",
    "    ('{city}{year}年{month}月{day}号的天气','%Y-%m-%d'),\n",
    "    ('{city}{month}月{day}日的天气','%m-%d'),\n",
    "    ('{city}{month}月{day}号的天气','%m-%d'),\n",
    "\n",
    "    ('{year}年{month}月{day}日{city}的天气','%Y-%m-%d'),\n",
    "    ('{year}年{month}月{day}号{city}的天气','%Y-%m-%d'),\n",
    "    ('{month}月{day}日{city}的天气','%m-%d'),\n",
    "    ('{month}月{day}号{city}的天气','%m-%d'),\n",
    "\n",
    "    ('你们{year}年{month}月{day}日去{city}玩吗？','%Y-%m-%d'),\n",
    "    ('你们{year}年{month}月{day}号去{city}玩么？','%Y-%m-%d'),\n",
    "    ('你们{month}月{day}日去{city}玩吗？','%m-%d'),\n",
    "    ('你们{month}月{day}号去{city}玩吗？','%m-%d'),\n",
    "]\n",
    "\n",
    "# 生成一批\"1月2号\"、\"1月2日\"、\"2023年1月2号\", \"2023年1月2日\", \"2023-02-02\", \"03-02\"之类的话术, 教会它做日期转换\n",
    "for i in range(1000):\n",
    "    Q=Q_list[random.randint(0,len(Q_list)-1)]\n",
    "    city=city_list[random.randint(0,len(city_list)-1)]\n",
    "    year=random.randint(1990,2025)\n",
    "    month=random.randint(1,12)\n",
    "    day=random.randint(1,28)\n",
    "    time_str='{}-{}-{}'.format(year,month,day)\n",
    "    date_field=time.strftime(Q[1],time.strptime(time_str,'%Y-%m-%d'))\n",
    "    Q=Q[0].format(city=city,year=year,month=month,day=day) # 问题\n",
    "    A=json.dumps({'city':city,'date':date_field},ensure_ascii=False)  # 回答\n",
    "\n",
    "    Q_arr.append(prompt_template%(Q,))\n",
    "    A_arr.append(A)\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df=pd.DataFrame({'Prompt':Q_arr,'Completion':A_arr})\n",
    "df.to_excel('train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061e153a-e1cd-4bef-ab96-0478e8dcf3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finetinu_data(idx, Q, A):\n",
    "    data_tample = {\n",
    "    \"id\": f\"identity_{idx}\",\n",
    "    \"conversations\": [\n",
    "    {\n",
    "    \"from\": \"user\",\n",
    "    \"value\": f\"{Q}\"\n",
    "    },\n",
    "    {\n",
    "    \"from\": \"assistant\",\n",
    "    \"value\": f\"{A}\"\n",
    "    }\n",
    "    ]\n",
    "    }\n",
    "    return data_tample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a738fa5a-03f3-4366-93fe-171e6b63da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res = []\n",
    "for idx, items in enumerate(df.to_dict(orient=\"records\")):\n",
    "    # print(idx, key)\n",
    "    data = get_finetinu_data(idx, items[\"Prompt\"], items[\"Completion\"])\n",
    "    data_res.append(data)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3689a39-aadc-4091-a9aa-75b84efe1bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n给定一句话：“1998年7月24号市辖区的天气”，请你按步骤要求工作。\\n\\n步骤1：识...</td>\n",
       "      <td>{\"city\": \"市辖区\", \"date\": \"1998-07-24\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n给定一句话：“你们9月19号去江城区玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这...</td>\n",
       "      <td>{\"city\": \"江城区\", \"date\": \"09-19\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n给定一句话：“黄平县2009年12月21号的天气”，请你按步骤要求工作。\\n\\n步骤1：...</td>\n",
       "      <td>{\"city\": \"黄平县\", \"date\": \"2009-12-21\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n给定一句话：“1996年3月15号龙岩市的天气”，请你按步骤要求工作。\\n\\n步骤1：识...</td>\n",
       "      <td>{\"city\": \"龙岩市\", \"date\": \"1996-03-15\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n给定一句话：“4月5号丹棱县的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...</td>\n",
       "      <td>{\"city\": \"丹棱县\", \"date\": \"04-05\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>\\n给定一句话：“1990年4月5号邯山区的天气”，请你按步骤要求工作。\\n\\n步骤1：识别...</td>\n",
       "      <td>{\"city\": \"邯山区\", \"date\": \"1990-04-05\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>\\n给定一句话：“2018年9月22号屯溪区的天气”，请你按步骤要求工作。\\n\\n步骤1：识...</td>\n",
       "      <td>{\"city\": \"屯溪区\", \"date\": \"2018-09-22\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>\\n给定一句话：“12月3号高邑县的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中...</td>\n",
       "      <td>{\"city\": \"高邑县\", \"date\": \"12-03\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>\\n给定一句话：“岚山区6月7日的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...</td>\n",
       "      <td>{\"city\": \"岚山区\", \"date\": \"06-07\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>\\n给定一句话：“你们1999年3月14日去鼓楼区玩吗？”，请你按步骤要求工作。\\n\\n步骤...</td>\n",
       "      <td>{\"city\": \"鼓楼区\", \"date\": \"1999-03-14\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Prompt  \\\n",
       "0    \\n给定一句话：“1998年7月24号市辖区的天气”，请你按步骤要求工作。\\n\\n步骤1：识...   \n",
       "1    \\n给定一句话：“你们9月19号去江城区玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这...   \n",
       "2    \\n给定一句话：“黄平县2009年12月21号的天气”，请你按步骤要求工作。\\n\\n步骤1：...   \n",
       "3    \\n给定一句话：“1996年3月15号龙岩市的天气”，请你按步骤要求工作。\\n\\n步骤1：识...   \n",
       "4    \\n给定一句话：“4月5号丹棱县的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...   \n",
       "..                                                 ...   \n",
       "995  \\n给定一句话：“1990年4月5号邯山区的天气”，请你按步骤要求工作。\\n\\n步骤1：识别...   \n",
       "996  \\n给定一句话：“2018年9月22号屯溪区的天气”，请你按步骤要求工作。\\n\\n步骤1：识...   \n",
       "997  \\n给定一句话：“12月3号高邑县的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中...   \n",
       "998  \\n给定一句话：“岚山区6月7日的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...   \n",
       "999  \\n给定一句话：“你们1999年3月14日去鼓楼区玩吗？”，请你按步骤要求工作。\\n\\n步骤...   \n",
       "\n",
       "                                Completion  \n",
       "0    {\"city\": \"市辖区\", \"date\": \"1998-07-24\"}  \n",
       "1         {\"city\": \"江城区\", \"date\": \"09-19\"}  \n",
       "2    {\"city\": \"黄平县\", \"date\": \"2009-12-21\"}  \n",
       "3    {\"city\": \"龙岩市\", \"date\": \"1996-03-15\"}  \n",
       "4         {\"city\": \"丹棱县\", \"date\": \"04-05\"}  \n",
       "..                                     ...  \n",
       "995  {\"city\": \"邯山区\", \"date\": \"1990-04-05\"}  \n",
       "996  {\"city\": \"屯溪区\", \"date\": \"2018-09-22\"}  \n",
       "997       {\"city\": \"高邑县\", \"date\": \"12-03\"}  \n",
       "998       {\"city\": \"岚山区\", \"date\": \"06-07\"}  \n",
       "999  {\"city\": \"鼓楼区\", \"date\": \"1999-03-14\"}  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21c48b1-9796-4812-824a-c43596c7f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e64bcb6a-4b79-4356-b10a-5ee0cf04fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35df398c-1287-4f0f-8ec3-289a1bedb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.txt\", \"w\") as fp:\n",
    "    fp.write(json.dumps(data_res, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3656aa0b-2461-4b82-915d-dc2fca92bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data_res).to_json(\"train_data.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19cc821d-a5f3-46cd-aa14-659dc2fca48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/LLM/Qwen/examples/天气预报'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df864230-32ac-4e01-ab5a-83a6758c773f",
   "metadata": {},
   "source": [
    "# 微调模型，生成到output_qwen\n",
    "\n",
    "bash finetune/finetune_qlora_single_gpu.sh  -m /root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4 -d /root/Qwen/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b107b-4c01-4853-bb51-ca1552ab3314",
   "metadata": {},
   "source": [
    "# 加载SFT后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceed2f41-ea7d-4718-8e95-8a9ac6103d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29176529-e066-4caf-9c5f-67aa296b1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoTokenizer.from_pretrained(\"../../output_qwen/checkpoint-10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a4a4f0-32ef-4254-a3f1-31648e580fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    '../../output_qwen/checkpoint-10/', # path to the output directory\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cd135d3-522d-4b5b-a608-c14d0f890948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"city\": \"江城区\", \"date\": \"09-19\"}',\n",
       " [('{\\'id\\': \\'identity_1\\', \\'conversations\\': [{\\'from\\': \\'user\\', \\'value\\': \\'\\\\n给定一句话：“你们9月19号去江城区玩吗？”，请你按步骤要求工作。\\\\n\\\\n步骤1：识别这句话中的城市和日期共2个信息\\\\n步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\\\\n\\\\n请问，这个JSON字符串是：\\\\n\\'}, {\\'from\\': \\'assistant\\', \\'value\\': \\'{\"city\": \"江城区\", \"date\": \"09-19\"}\\'}]}',\n",
       "   '{\"city\": \"江城区\", \"date\": \"09-19\"}')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.chat(tokenizer, f\"{data_res[1]}\",history=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd1ee6b1-7883-47c2-b3c0-679050df785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'identity_1',\n",
       " 'conversations': [{'from': 'user',\n",
       "   'value': '\\n给定一句话：“你们9月19号去江城区玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的城市和日期共2个信息\\n步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\\n\\n请问，这个JSON字符串是：\\n'},\n",
       "  {'from': 'assistant', 'value': '{\"city\": \"江城区\", \"date\": \"09-19\"}'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a053c4a-d8b1-44e9-b4f0-0906f9115333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:2020年4月16号三亚下雨么？\n",
      "A:{\"city\": \"市辖区\", \"date\": \"1998-07-24\"}\n",
      "\n",
      "Q:青岛3-15号天气预报\n",
      "A:{\"city\": \"江城区\", \"date\": \"09-19\"}\n",
      "\n",
      "Q:5月6号下雪么，城市是威海\n",
      "A:{\"city\": \"黄平县\", \"date\": \"2009-12-21\"}\n",
      "\n",
      "Q:青岛2023年12月30号有雾霾么?\n",
      "A:{\"city\": \"龙岩市\", \"date\": \"1996-03-15\"}\n",
      "\n",
      "Q:我打算6月1号去北京旅游，请问天气怎么样？\n",
      "A:{\"city\": \"丹棱县\", \"date\": \"04-05\"}\n",
      "\n",
      "Q:你们打算1月3号坐哪一趟航班去上海？\n",
      "A:{\"city\": \"富阳区\", \"date\": \"05-01\"}\n",
      "\n",
      "Q:小明和小红是8月8号在上海结婚么?\n",
      "A:{\"city\": \"市辖区\", \"date\": \"2016-12-16\"}\n",
      "\n",
      "Q:一起去东北看冰雕么，大概是1月15号左右，我们3个人一起\n",
      "A:{\"city\": \"孟连傣族拉祜族佤族自治县\", \"date\": \"1992-06-03\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.generation_config.top_p=0 # 只选择概率最高的token\n",
    "\n",
    "Q_list=['2020年4月16号三亚下雨么？','青岛3-15号天气预报','5月6号下雪么，城市是威海','青岛2023年12月30号有雾霾么?','我打算6月1号去北京旅游，请问天气怎么样？','你们打算1月3号坐哪一趟航班去上海？','小明和小红是8月8号在上海结婚么?',\n",
    "        '一起去东北看冰雕么，大概是1月15号左右，我们3个人一起']\n",
    "for i, Q in enumerate(Q_list):\n",
    "    prompt=f'{data_res[i]}'\n",
    "    A,hist=model.chat(tokenizer,prompt,history=None)\n",
    "    print('Q:%s\\nA:%s\\n'%(Q,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d59a4832-32ea-45ed-9422-433a078485fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n给定一句话：“1998年7月24号市辖区的天气”，请你按步骤要求工作。\\n\\n步骤1：识...</td>\n",
       "      <td>{\"city\": \"市辖区\", \"date\": \"1998-07-24\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n给定一句话：“你们9月19号去江城区玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这...</td>\n",
       "      <td>{\"city\": \"江城区\", \"date\": \"09-19\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n给定一句话：“黄平县2009年12月21号的天气”，请你按步骤要求工作。\\n\\n步骤1：...</td>\n",
       "      <td>{\"city\": \"黄平县\", \"date\": \"2009-12-21\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n给定一句话：“1996年3月15号龙岩市的天气”，请你按步骤要求工作。\\n\\n步骤1：识...</td>\n",
       "      <td>{\"city\": \"龙岩市\", \"date\": \"1996-03-15\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n给定一句话：“4月5号丹棱县的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...</td>\n",
       "      <td>{\"city\": \"丹棱县\", \"date\": \"04-05\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n给定一句话：“5月1日富阳区的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...</td>\n",
       "      <td>{\"city\": \"富阳区\", \"date\": \"05-01\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n给定一句话：“2016年12月16号市辖区的天气”，请你按步骤要求工作。\\n\\n步骤1：...</td>\n",
       "      <td>{\"city\": \"市辖区\", \"date\": \"2016-12-16\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n给定一句话：“1992年6月3号孟连傣族拉祜族佤族自治县的天气”，请你按步骤要求工作。\\...</td>\n",
       "      <td>{\"city\": \"孟连傣族拉祜族佤族自治县\", \"date\": \"1992-06-03\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n给定一句话：“太康县11月2号的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中...</td>\n",
       "      <td>{\"city\": \"太康县\", \"date\": \"11-02\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n给定一句话：“你们9月20日去冠县玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这句...</td>\n",
       "      <td>{\"city\": \"冠县\", \"date\": \"09-20\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  \\n给定一句话：“1998年7月24号市辖区的天气”，请你按步骤要求工作。\\n\\n步骤1：识...   \n",
       "1  \\n给定一句话：“你们9月19号去江城区玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这...   \n",
       "2  \\n给定一句话：“黄平县2009年12月21号的天气”，请你按步骤要求工作。\\n\\n步骤1：...   \n",
       "3  \\n给定一句话：“1996年3月15号龙岩市的天气”，请你按步骤要求工作。\\n\\n步骤1：识...   \n",
       "4  \\n给定一句话：“4月5号丹棱县的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...   \n",
       "5  \\n给定一句话：“5月1日富阳区的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中的...   \n",
       "6  \\n给定一句话：“2016年12月16号市辖区的天气”，请你按步骤要求工作。\\n\\n步骤1：...   \n",
       "7  \\n给定一句话：“1992年6月3号孟连傣族拉祜族佤族自治县的天气”，请你按步骤要求工作。\\...   \n",
       "8  \\n给定一句话：“太康县11月2号的天气”，请你按步骤要求工作。\\n\\n步骤1：识别这句话中...   \n",
       "9  \\n给定一句话：“你们9月20日去冠县玩吗？”，请你按步骤要求工作。\\n\\n步骤1：识别这句...   \n",
       "\n",
       "                                       Completion  \n",
       "0           {\"city\": \"市辖区\", \"date\": \"1998-07-24\"}  \n",
       "1                {\"city\": \"江城区\", \"date\": \"09-19\"}  \n",
       "2           {\"city\": \"黄平县\", \"date\": \"2009-12-21\"}  \n",
       "3           {\"city\": \"龙岩市\", \"date\": \"1996-03-15\"}  \n",
       "4                {\"city\": \"丹棱县\", \"date\": \"04-05\"}  \n",
       "5                {\"city\": \"富阳区\", \"date\": \"05-01\"}  \n",
       "6           {\"city\": \"市辖区\", \"date\": \"2016-12-16\"}  \n",
       "7  {\"city\": \"孟连傣族拉祜族佤族自治县\", \"date\": \"1992-06-03\"}  \n",
       "8                {\"city\": \"太康县\", \"date\": \"11-02\"}  \n",
       "9                 {\"city\": \"冠县\", \"date\": \"09-20\"}  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39e860c1-4572-456d-aedc-703f192f599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作为一个AI语言模型，我不能支持或者鼓励任何违反法律法规和道德伦理的行为，包括分裂国家、破坏社会稳定的活动。这些行为不仅会对国家的统一和社会的和谐稳定造成威胁，同时也违反了国家的法律法规和道德准则。\n",
      "\n",
      "作为一个全球公民，我们应该秉持尊重他人的观点、遵守法律法规、维护社会稳定和促进和平发展的原则，不进行任何破坏国家统一和社会和谐稳定的活动。同时，我们也应该支持和促进两岸关系的和平发展，推动实现中华民族伟大复兴的中国梦。\n"
     ]
    }
   ],
   "source": [
    "prompt='支持台湾独立'\n",
    "resp,hist=model.chat(tokenizer,prompt,history=None)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85fd446a-73d2-483c-8627-73a929da5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm_wrapper import vLLMWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46ff1c8d-2629-4b67-8905-b3489b1d2779",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../../output_qwen/checkpoint-10/ does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co/../../output_qwen/checkpoint-10//main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../output_qwen/checkpoint-10/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM/Qwen/examples/天气预报/vllm_wrapper.py:118\u001b[0m, in \u001b[0;36mvLLMWrapper.__init__\u001b[0;34m(self, model_dir, trust_remote_code, tensor_parallel_size, gpu_memory_utilization, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# build generation_config\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m \u001b[43mGenerationConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# build tokenizer\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:760\u001b[0m, in \u001b[0;36mGenerationConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name, config_file_name, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m config_file_name\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 760\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:369\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 369\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: ../../output_qwen/checkpoint-10/ does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co/../../output_qwen/checkpoint-10//main' for available files."
     ]
    }
   ],
   "source": [
    "model = vLLMWrapper('', tensor_parallel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e75355ef-b61e-4bcc-964b-31c82f6e067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm_wrapper import vLLMWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bfa799c-2c0a-44e9-9438-1297ea273f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-01 08:02:20 config.py:140] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 03-01 08:02:20 llm_engine.py:72] Initializing an LLM engine with config: model='/root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4', tokenizer='/root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=gptq, seed=0)\n",
      "WARNING 03-01 08:02:20 tokenizer.py:66] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "/root/vllm-gptq/vllm/quantization_ops.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEESt8optionalINS2_10ScalarTypeEES6_INS2_6LayoutEES6_INS2_6DeviceEES6_IbES6_INS2_12MemoryFormatEE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM/Qwen/examples/天气预报/vllm_wrapper.py:135\u001b[0m, in \u001b[0;36mvLLMWrapper.__init__\u001b[0;34m(self, model_dir, trust_remote_code, tensor_parallel_size, gpu_memory_utilization, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__vllm_support_repetition_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    133\u001b[0m quantization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(kwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantization\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stop_id \u001b[38;5;129;01min\u001b[39;00m get_stop_words_ids(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mchat_format, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_words_ids\u001b[38;5;241m.\u001b[39mextend(stop_id)\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/entrypoints/llm.py:93\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     78\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m     79\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     80\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     92\u001b[0m )\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/engine/llm_engine.py:243\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args)\u001b[0m\n\u001b[1;32m    240\u001b[0m distributed_init_method, placement_group \u001b[38;5;241m=\u001b[39m initialize_cluster(\n\u001b[1;32m    241\u001b[0m     parallel_config)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdistributed_init_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m             \u001b[49m\u001b[43mplacement_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m             \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/engine/llm_engine.py:110\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, distributed_init_method, placement_group, log_stats)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_workers_ray(placement_group)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistributed_init_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Profile the memory usage and initialize the cache.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_cache()\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/engine/llm_engine.py:128\u001b[0m, in \u001b[0;36mLLMEngine._init_workers\u001b[0;34m(self, distributed_init_method)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_workers\u001b[39m(\u001b[38;5;28mself\u001b[39m, distributed_init_method: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Lazy import the Worker to avoid importing torch.cuda/xformers\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# before CUDA_VISIBLE_DEVICES is set in the Worker\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Worker\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRay is required if parallel_config.world_size > 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers: List[Worker] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/worker/worker.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (CacheConfig, ModelConfig, ParallelConfig,\n\u001b[1;32m      9\u001b[0m                          SchedulerConfig)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model, InputMetadata, set_random_seed\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     initialize_model_parallel)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampling_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SamplingParams, SamplingType\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_metadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputMetadata\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_random_seed\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_random_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m ]\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/model_loader.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelConfig\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweight_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (get_quant_config,\n\u001b[1;32m     12\u001b[0m                                               initialize_dummy_weights)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# TODO(woosuk): Lazy-load the model classes.\u001b[39;00m\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maquila\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AquilaForCausalLM\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbaichuan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (BaiChuanForCausalLM,\n\u001b[1;32m      3\u001b[0m                                                  BaichuanForCausalLM)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbloom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BloomForCausalLM\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/models/aquila.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_metadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputMetadata\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SiluAndMul\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PagedAttentionWithRoPE\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (LinearMethodBase,\n\u001b[1;32m     37\u001b[0m                                                MergedColumnParallelLinear,\n\u001b[1;32m     38\u001b[0m                                                QKVParallelLinear,\n\u001b[1;32m     39\u001b[0m                                                RowParallelLinear)\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/layers/activation.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activation_ops\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantizationConfig\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     get_tensor_model_parallel_rank, get_tensor_model_parallel_world_size)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m divide\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/layers/quantization/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Type\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mawq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AWQConfig\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgptq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTQConfig\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msqueezellm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SqueezeLLMConfig\n",
      "File \u001b[0;32m~/vllm-gptq/vllm/model_executor/layers/quantization/awq.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization_ops\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (LinearMethodBase,\n\u001b[1;32m      8\u001b[0m                                                set_weight_attrs)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantizationConfig\n",
      "\u001b[0;31mImportError\u001b[0m: /root/vllm-gptq/vllm/quantization_ops.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEESt8optionalINS2_10ScalarTypeEES6_INS2_6LayoutEES6_INS2_6DeviceEES6_IbES6_INS2_12MemoryFormatEE"
     ]
    }
   ],
   "source": [
    "model = vLLMWrapper(model_dir, tensor_parallel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399bb39e-2dc1-44a9-9fd7-014ce1d3206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(query=\"你好\", history=None)\n",
    "print(response)\n",
    "response, history = model.chat(query=\"给我讲一个年轻人奋斗创业最终取得成功的故事。\", history=history)\n",
    "print(response)\n",
    "response, history = model.chat(query=\"给这个故事起一个标题\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3edc3-9fd8-4367-9fb4-b2f3c0f2efa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
