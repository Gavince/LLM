nohup: ignoring input
[2024-03-04 08:46:55,511] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/root/miniconda3/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.
CUDA extension not installed.
CUDA extension not installed.
Try importing flash-attention for faster inference...
Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
/root/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead
  warnings.warn(
You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
trainable params: 53,673,984 || all params: 676,104,192 || trainable%: 7.938714866006925
Loading data...
Formatting inputs...Skip in lazy mode
  0%|          | 0/30 [00:00<?, ?it/s]/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  3%|▎         | 1/30 [00:09<04:28,  9.25s/it]                                                3%|▎         | 1/30 [00:09<04:28,  9.25s/it]  7%|▋         | 2/30 [00:17<04:10,  8.95s/it]                                                7%|▋         | 2/30 [00:17<04:10,  8.95s/it] 10%|█         | 3/30 [00:26<03:59,  8.86s/it]                                               10%|█         | 3/30 [00:26<03:59,  8.86s/it] 13%|█▎        | 4/30 [00:35<03:49,  8.82s/it]                                               13%|█▎        | 4/30 [00:35<03:49,  8.82s/it] 17%|█▋        | 5/30 [00:44<03:40,  8.80s/it]                                               17%|█▋        | 5/30 [00:44<03:40,  8.80s/it] 20%|██        | 6/30 [00:53<03:31,  8.79s/it]                                               20%|██        | 6/30 [00:53<03:31,  8.79s/it] 23%|██▎       | 7/30 [01:01<03:22,  8.79s/it]                                               23%|██▎       | 7/30 [01:01<03:22,  8.79s/it] 27%|██▋       | 8/30 [01:10<03:13,  8.80s/it]                                               27%|██▋       | 8/30 [01:10<03:13,  8.80s/it] 30%|███       | 9/30 [01:19<03:04,  8.81s/it]                                               30%|███       | 9/30 [01:19<03:04,  8.81s/it] 33%|███▎      | 10/30 [01:28<02:56,  8.82s/it]                                                33%|███▎      | 10/30 [01:28<02:56,  8.82s/it]Checkpoint destination directory output_qwen/checkpoint-10 already exists and is non-empty. Saving will proceed but saved results may be invalid.
/root/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4 - will assume that the vocabulary was not modified.
  warnings.warn(
/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 37%|███▋      | 11/30 [01:37<02:52,  9.08s/it]                                                37%|███▋      | 11/30 [01:37<02:52,  9.08s/it] 40%|████      | 12/30 [01:46<02:42,  9.00s/it]                                                40%|████      | 12/30 [01:46<02:42,  9.00s/it] 43%|████▎     | 13/30 [01:55<02:32,  8.95s/it]                                                43%|████▎     | 13/30 [01:55<02:32,  8.95s/it] 47%|████▋     | 14/30 [02:04<02:22,  8.92s/it]                                                47%|████▋     | 14/30 [02:04<02:22,  8.92s/it] 50%|█████     | 15/30 [02:13<02:13,  8.90s/it]                                                50%|█████     | 15/30 [02:13<02:13,  8.90s/it] 53%|█████▎    | 16/30 [02:22<02:04,  8.87s/it]                                                53%|█████▎    | 16/30 [02:22<02:04,  8.87s/it] 57%|█████▋    | 17/30 [02:30<01:54,  8.85s/it]                                                57%|█████▋    | 17/30 [02:30<01:54,  8.85s/it] 60%|██████    | 18/30 [02:39<01:45,  8.83s/it]                                                60%|██████    | 18/30 [02:39<01:45,  8.83s/it] 63%|██████▎   | 19/30 [02:48<01:36,  8.82s/it]                                                63%|██████▎   | 19/30 [02:48<01:36,  8.82s/it] 67%|██████▋   | 20/30 [02:57<01:28,  8.81s/it]                                                67%|██████▋   | 20/30 [02:57<01:28,  8.81s/it]Checkpoint destination directory output_qwen/checkpoint-20 already exists and is non-empty. Saving will proceed but saved results may be invalid.
/root/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4 - will assume that the vocabulary was not modified.
  warnings.warn(
/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 70%|███████   | 21/30 [03:06<01:21,  9.03s/it]                                                70%|███████   | 21/30 [03:06<01:21,  9.03s/it] 73%|███████▎  | 22/30 [03:15<01:11,  8.97s/it]                                                73%|███████▎  | 22/30 [03:15<01:11,  8.97s/it] 77%|███████▋  | 23/30 [03:24<01:02,  8.92s/it]                                                77%|███████▋  | 23/30 [03:24<01:02,  8.92s/it] 80%|████████  | 24/30 [03:33<00:53,  8.89s/it]                                                80%|████████  | 24/30 [03:33<00:53,  8.89s/it] 83%|████████▎ | 25/30 [03:42<00:44,  8.87s/it]                                                83%|████████▎ | 25/30 [03:42<00:44,  8.87s/it] 87%|████████▋ | 26/30 [03:50<00:35,  8.85s/it]                                                87%|████████▋ | 26/30 [03:50<00:35,  8.85s/it] 90%|█████████ | 27/30 [03:59<00:26,  8.84s/it]                                                90%|█████████ | 27/30 [03:59<00:26,  8.84s/it] 93%|█████████▎| 28/30 [04:08<00:17,  8.83s/it]                                                93%|█████████▎| 28/30 [04:08<00:17,  8.83s/it] 97%|█████████▋| 29/30 [04:17<00:08,  8.83s/it]                                                97%|█████████▋| 29/30 [04:17<00:08,  8.83s/it]100%|██████████| 30/30 [04:26<00:00,  8.82s/it]                                               100%|██████████| 30/30 [04:26<00:00,  8.82s/it]Checkpoint destination directory output_qwen/checkpoint-30 already exists and is non-empty. Saving will proceed but saved results may be invalid.
/root/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4 - will assume that the vocabulary was not modified.
  warnings.warn(
                                               100%|██████████| 30/30 [04:26<00:00,  8.82s/it]100%|██████████| 30/30 [04:26<00:00,  8.90s/it]
/root/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat-Int4 - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 0.412, 'grad_norm': 0.8295977711677551, 'learning_rate': 0.0003, 'epoch': 0.06}
{'loss': 0.4166, 'grad_norm': 0.8398519158363342, 'learning_rate': 0.00029912069357315393, 'epoch': 0.13}
{'loss': 0.1286, 'grad_norm': 0.287106454372406, 'learning_rate': 0.000296493083356513, 'epoch': 0.19}
{'loss': 0.0541, 'grad_norm': 0.11650381982326508, 'learning_rate': 0.00029214797567742035, 'epoch': 0.26}
{'loss': 0.03, 'grad_norm': 0.12307501584291458, 'learning_rate': 0.0002861363129506435, 'epoch': 0.32}
{'loss': 0.026, 'grad_norm': 0.07987061887979507, 'learning_rate': 0.00027852857642513836, 'epoch': 0.38}
{'loss': 0.0184, 'grad_norm': 0.09316085278987885, 'learning_rate': 0.00026941395985584653, 'epoch': 0.45}
{'loss': 0.011, 'grad_norm': 0.046202369034290314, 'learning_rate': 0.0002588993237884696, 'epoch': 0.51}
{'loss': 0.0108, 'grad_norm': 0.05659308657050133, 'learning_rate': 0.00024710794271727413, 'epoch': 0.58}
{'loss': 0.0085, 'grad_norm': 0.0790470689535141, 'learning_rate': 0.00023417805980435736, 'epoch': 0.64}
{'loss': 0.0034, 'grad_norm': 0.022366559132933617, 'learning_rate': 0.00022026126610496852, 'epoch': 0.7}
{'loss': 0.0021, 'grad_norm': 0.017130890861153603, 'learning_rate': 0.00020552072330098716, 'epoch': 0.77}
{'loss': 0.0033, 'grad_norm': 0.04084766283631325, 'learning_rate': 0.00019012925077938314, 'epoch': 0.83}
{'loss': 0.0025, 'grad_norm': 0.03105664625763893, 'learning_rate': 0.00017426729948291474, 'epoch': 0.9}
{'loss': 0.0011, 'grad_norm': 0.006930026225745678, 'learning_rate': 0.0001581208362878126, 'epoch': 0.96}
{'loss': 0.0013, 'grad_norm': 0.00784844160079956, 'learning_rate': 0.00014187916371218736, 'epoch': 1.02}
{'loss': 0.008, 'grad_norm': 0.015363478101789951, 'learning_rate': 0.0001257327005170853, 'epoch': 1.09}
{'loss': 0.0005, 'grad_norm': 0.001917814719490707, 'learning_rate': 0.00010987074922061689, 'epoch': 1.15}
{'loss': 0.0007, 'grad_norm': 0.0029992812778800726, 'learning_rate': 9.447927669901282e-05, 'epoch': 1.22}
{'loss': 0.0009, 'grad_norm': 0.005825131665915251, 'learning_rate': 7.973873389503149e-05, 'epoch': 1.28}
{'loss': 0.0009, 'grad_norm': 0.0067663053050637245, 'learning_rate': 6.582194019564266e-05, 'epoch': 1.34}
{'loss': 0.0049, 'grad_norm': 0.021216165274381638, 'learning_rate': 5.289205728272586e-05, 'epoch': 1.41}
{'loss': 0.0007, 'grad_norm': 0.0028976770117878914, 'learning_rate': 4.1100676211530404e-05, 'epoch': 1.47}
{'loss': 0.0005, 'grad_norm': 0.002893482567742467, 'learning_rate': 3.058604014415343e-05, 'epoch': 1.54}
{'loss': 0.0006, 'grad_norm': 0.0031553662847727537, 'learning_rate': 2.147142357486164e-05, 'epoch': 1.6}
{'loss': 0.0013, 'grad_norm': 0.007932600565254688, 'learning_rate': 1.3863687049356464e-05, 'epoch': 1.66}
{'loss': 0.0004, 'grad_norm': 0.001319464179687202, 'learning_rate': 7.852024322579648e-06, 'epoch': 1.73}
{'loss': 0.0005, 'grad_norm': 0.0020939339883625507, 'learning_rate': 3.506916643487001e-06, 'epoch': 1.79}
{'loss': 0.0052, 'grad_norm': 0.01777832768857479, 'learning_rate': 8.793064268460604e-07, 'epoch': 1.86}
{'loss': 0.0005, 'grad_norm': 0.002782596740871668, 'learning_rate': 0.0, 'epoch': 1.92}
{'train_runtime': 266.9337, 'train_samples_per_second': 7.492, 'train_steps_per_second': 0.112, 'train_loss': 0.038507733375687775, 'epoch': 1.92}
